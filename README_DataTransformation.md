# STUDENT ANALYST - Data Transformation System

## Overview
Professional data transformation engine that converts raw Alpha Vantage data into standardized, validated format.

## Key Features
- Date normalization to ISO 8601 UTC
- Automatic stock split detection and adjustment
- Volume standardization and anomaly detection
- Comprehensive data quality assessment
- Real-time processing with performance monitoring

## Usage
```typescript
const result = await dataTransformationService.transformAlphaVantageData(rawData, {
  adjustForSplits: true,
  detectAnomalies: true,
  validateData: true
});
```

## Quality Metrics
- Quality Score: 0-100 comprehensive scoring
- Anomaly Detection: Price spikes, volume spikes, data gaps
- Confidence Levels: Price, volume, and date confidence

## Demo Interface
Access via "üîÑ Data Transformation System" button in the main application.

## Architecture
- StandardizedData models for type safety
- DataTransformationService for processing
- DataTransformationDemo for testing and visualization

## üéØ Overview

The Data Transformation & Normalization System is a sophisticated engine that converts raw financial data from various sources (primarily Alpha Vantage) into a standardized, validated, and enriched format ready for advanced financial analysis.

## üèóÔ∏è Architecture

### Core Components

1. **StandardizedData Models** (`src/models/StandardizedData.ts`)
   - Universal data schema for all financial data
   - Type-safe interfaces with comprehensive metadata
   - Quality metrics and validation flags
   - Corporate action tracking

2. **DataTransformationService** (`src/services/DataTransformationService.ts`)
   - Main transformation engine
   - Singleton pattern for consistent processing
   - Configurable transformation options
   - Performance monitoring and caching

3. **DataTransformationDemo** (`src/components/DataTransformationDemo.tsx`)
   - Professional UI for testing and demonstration
   - Real-time processing visualization
   - Quality assessment dashboard
   - Interactive data exploration

## üìä Data Flow

```
Raw Alpha Vantage Data
         ‚Üì
   Input Validation
         ‚Üì
   Date Normalization (ISO 8601 UTC)
         ‚Üì
   Price Adjustment (Splits/Dividends)
         ‚Üì
   Volume Standardization
         ‚Üì
   Anomaly Detection
         ‚Üì
   Quality Assessment
         ‚Üì
   Standardized Dataset
```

## üîß Key Features

### 1. Date Normalization
- **Input**: Various date formats from Alpha Vantage
- **Output**: ISO 8601 format (YYYY-MM-DD) in UTC
- **Validation**: Date range validation, future date tolerance
- **Market Logic**: Weekend/holiday detection

### 2. Price Adjustment
- **Split Detection**: Automatic detection using price/volume patterns
- **Retroactive Adjustment**: Historical price correction
- **Common Ratios**: Support for 2:1, 3:1, 3:2, 4:1, 5:1 splits
- **Raw Price Preservation**: Original prices stored for reference

### 3. Volume Processing
- **Unit Standardization**: All volumes in individual shares
- **Heuristic Detection**: Automatic detection of K/M units
- **Anomaly Detection**: Volume spike identification
- **Zero Volume Handling**: Holiday/halt detection

### 4. Data Quality Assessment
- **Quality Score**: 0-100 comprehensive scoring
- **Confidence Metrics**: Price, volume, and date confidence
- **Anomaly Flagging**: Price spikes, volume spikes, data gaps
- **Validation Rules**: OHLC consistency, logical constraints

### 5. Corporate Action Detection
- **Split Detection**: Price jump + volume spike analysis
- **Adjustment Calculation**: Automatic factor computation
- **Historical Application**: Retroactive price adjustments
- **Metadata Enrichment**: Action tracking and documentation

## üöÄ Usage Examples

### Basic Transformation

```typescript
import { dataTransformationService } from './services/DataTransformationService';
import { alphaVantageService } from './services/AlphaVantageService';

// Fetch raw data
const rawData = await alphaVantageService.getStockData({
  symbol: 'AAPL',
  timeframe: 'DAILY'
});

// Transform to standardized format
const result = await dataTransformationService.transformAlphaVantageData(rawData, {
  adjustForSplits: true,
  adjustForDividends: true,
  detectAnomalies: true,
  validateData: true,
  minQualityScore: 80
});

if (result.success) {
  const normalizedData = result.data;
  console.log(`Quality Score: ${normalizedData.quality.qualityScore}%`);
  console.log(`Data Points: ${normalizedData.data.length}`);
  console.log(`Anomalies: ${normalizedData.quality.anomalies.length}`);
}
```

### Advanced Configuration

```typescript
const transformationOptions = {
  adjustForSplits: true,
  adjustForDividends: true,
  detectAnomalies: true,
  validateData: true,
  minQualityScore: 70,
  allowPartialData: true,
  enableCaching: true,
  batchSize: 100
};

const result = await dataTransformationService.transformAlphaVantageData(
  rawData, 
  transformationOptions
);
```

### Quality Assessment

```typescript
const quality = result.data.quality;

console.log('Quality Metrics:');
console.log(`- Overall Score: ${quality.qualityScore}%`);
console.log(`- Price Confidence: ${quality.priceConfidence}%`);
console.log(`- Volume Confidence: ${quality.volumeConfidence}%`);
console.log(`- Date Confidence: ${quality.dateConfidence}%`);

console.log('Data Issues:');
console.log(`- Price Anomalies: ${quality.hasPriceAnomalies}`);
console.log(`- Volume Anomalies: ${quality.hasVolumeAnomalies}`);
console.log(`- Date Gaps: ${quality.hasDateGaps}`);

// Detailed anomaly analysis
quality.anomalies.forEach(anomaly => {
  console.log(`${anomaly.date}: ${anomaly.description} (${anomaly.severity})`);
});
```

## üìà Data Model

### NormalizedPricePoint
```typescript
interface NormalizedPricePoint {
  date: string;              // ISO 8601 format (YYYY-MM-DD)
  open: number;              // Split-adjusted price
  high: number;              // Split-adjusted price
  low: number;               // Split-adjusted price
  close: number;             // Split-adjusted price
  volume: number;            // Individual shares
  adjustedClose?: number;    // Dividend-adjusted close
  rawOpen?: number;          // Original unadjusted price
  rawHigh?: number;          // Original unadjusted price
  rawLow?: number;           // Original unadjusted price
  rawClose?: number;         // Original unadjusted price
  splitCoefficient?: number; // Split ratio (2.0 for 2:1 split)
  dividendAmount?: number;   // Dividend amount if any
  isAdjusted: boolean;       // True if prices were adjusted
  hasAnomalies: boolean;     // True if anomalies detected
  validationFlags: string[]; // List of validation issues
  marketOpen: boolean;       // True if market was open
  tradingHalted?: boolean;   // True if trading was halted
}
```

### NormalizedDataset
```typescript
interface NormalizedDataset {
  symbol: string;            // Stock symbol (uppercase)
  exchange?: string;         // Exchange identifier
  currency: string;          // ISO currency code (USD, EUR, etc.)
  timeframe: StandardTimeframe; // DAILY, WEEKLY, MONTHLY, etc.
  dataType: 'EQUITY' | 'INDEX' | 'ETF' | 'CRYPTO' | 'FOREX';
  data: NormalizedPricePoint[]; // Sorted by date (newest first)
  metadata: NormalizedMetadata; // Comprehensive metadata
  quality: DataQuality;      // Quality assessment
  processing: ProcessingInfo; // Processing information
}
```

## üîç Quality Metrics

### Quality Score Calculation
- **Base Score**: 100 points
- **Anomaly Penalty**: -30 points per anomalous data point percentage
- **Validation Penalty**: -20 points per validation issue percentage
- **Range**: 0-100 (higher is better)

### Quality Thresholds
- **High Quality**: ‚â•90 points
- **Acceptable Quality**: ‚â•75 points
- **Low Quality**: ‚â•60 points
- **Poor Quality**: <60 points

### Confidence Metrics
- **Price Confidence**: Based on OHLC consistency and anomaly detection
- **Volume Confidence**: Based on volume pattern analysis
- **Date Confidence**: Based on date format and business logic validation

## üö® Anomaly Detection

### Price Anomalies
- **Price Spikes**: >50% daily change (configurable)
- **Invalid OHLC**: High < Low, Close outside High/Low range
- **Negative Prices**: Prices ‚â§ 0
- **Extreme Values**: Prices outside realistic ranges

### Volume Anomalies
- **Volume Spikes**: >50x average volume (configurable)
- **Zero Volume**: On trading days (potential data issue)
- **Negative Volume**: Invalid volume values

### Data Anomalies
- **Date Gaps**: Missing trading days
- **Duplicate Dates**: Same date appearing multiple times
- **Future Dates**: Dates beyond tolerance threshold
- **Invalid Dates**: Malformed or impossible dates

## ‚ö° Performance Optimization

### Caching Strategy
- **Split Detection Cache**: Corporate actions cached by symbol
- **Statistics Cache**: Expensive calculations cached
- **TTL Management**: Automatic cache expiration

### Processing Efficiency
- **Batch Processing**: Configurable batch sizes
- **Lazy Evaluation**: Expensive operations only when needed
- **Memory Management**: Efficient data structures

### Monitoring
- **Processing Time**: Millisecond-level timing
- **Throughput Metrics**: Records processed per second
- **Error Tracking**: Comprehensive error statistics
- **Success Rates**: Transformation success monitoring

## üõ†Ô∏è Configuration

### Validation Constants
```typescript
const VALIDATION_CONSTANTS = {
  MIN_PRICE: 0.01,                    // Minimum valid price
  MAX_PRICE: 1000000,                 // Maximum realistic price
  MAX_PRICE_CHANGE: 0.50,             // Maximum 50% daily change
  MIN_VOLUME: 0,                      // Minimum volume
  MAX_VOLUME_MULTIPLIER: 50,          // Volume spike threshold
  OLDEST_VALID_DATE: '1900-01-01',    // Oldest acceptable date
  FUTURE_DATE_TOLERANCE_DAYS: 1,      // Future date tolerance
  MIN_QUALITY_SCORE: 60,              // Minimum quality threshold
  HIGH_QUALITY_SCORE: 90              // High quality threshold
};
```

### Transformation Options
```typescript
interface TransformationOptions {
  adjustForSplits: boolean;      // Enable split adjustment
  adjustForDividends: boolean;   // Enable dividend adjustment
  detectAnomalies: boolean;      // Enable anomaly detection
  validateData: boolean;         // Enable data validation
  minQualityScore: number;       // Minimum acceptable quality
  allowPartialData: boolean;     // Allow low-quality data
  enableCaching: boolean;        // Enable result caching
  batchSize?: number;            // Processing batch size
}
```

## üß™ Testing & Validation

### Demo Interface
The `DataTransformationDemo` component provides:
- **Interactive Testing**: Real-time transformation testing
- **Quality Visualization**: Comprehensive quality dashboards
- **Data Exploration**: Detailed data point inspection
- **Performance Monitoring**: Processing time and metrics
- **Error Handling**: Graceful error display and recovery

### Test Scenarios
1. **Normal Data**: Standard OHLC data transformation
2. **Split Events**: Data with stock splits
3. **Anomalous Data**: Data with price/volume spikes
4. **Incomplete Data**: Missing or corrupted data points
5. **Edge Cases**: Extreme values and boundary conditions

## üîß Troubleshooting

### Common Issues

#### Low Quality Scores
- **Cause**: High number of anomalies or validation failures
- **Solution**: Review data source, adjust validation thresholds
- **Prevention**: Implement data source validation

#### Split Detection Failures
- **Cause**: Unusual split ratios or insufficient volume data
- **Solution**: Manual corporate action data integration
- **Prevention**: Enhanced split detection algorithms

#### Performance Issues
- **Cause**: Large datasets or complex transformations
- **Solution**: Enable caching, reduce batch sizes
- **Prevention**: Implement data pagination

#### Memory Usage
- **Cause**: Large datasets held in memory
- **Solution**: Streaming processing, garbage collection
- **Prevention**: Implement data streaming

### Error Codes
- **INVALID_INPUT**: Input data validation failed
- **TRANSFORMATION_FAILED**: Core transformation error
- **QUALITY_TOO_LOW**: Data quality below threshold
- **PROCESSING_TIMEOUT**: Transformation took too long
- **CACHE_ERROR**: Caching system failure

## üöÄ Future Enhancements

### Planned Features
1. **Multi-Source Support**: Yahoo Finance, IEX Cloud integration
2. **Real-Time Processing**: Live data transformation
3. **Machine Learning**: AI-powered anomaly detection
4. **Advanced Adjustments**: Complex corporate actions
5. **Data Streaming**: Real-time data pipelines

### Performance Improvements
1. **WebWorkers**: Background processing
2. **Compression**: Data compression for storage
3. **Indexing**: Fast data retrieval
4. **Clustering**: Distributed processing

## üìö API Reference

### DataTransformationService

#### Methods
- `transformAlphaVantageData(rawData, options)`: Main transformation method
- `getStatistics()`: Get processing statistics
- `clearCaches()`: Clear all caches

#### Events
- `transformation-started`: Transformation begins
- `transformation-completed`: Transformation finished
- `transformation-failed`: Transformation error
- `quality-assessed`: Quality assessment completed

### Utility Functions
- `isNormalizedPricePoint(obj)`: Type guard for price points
- `isNormalizedDataset(obj)`: Type guard for datasets
- `calculateQualityScore(data)`: Manual quality calculation
- `detectAnomalies(data)`: Manual anomaly detection

## üéØ Best Practices

### Data Processing
1. **Always validate input data** before transformation
2. **Use appropriate quality thresholds** for your use case
3. **Enable caching** for repeated transformations
4. **Monitor processing performance** regularly
5. **Handle errors gracefully** with fallback strategies

### Quality Management
1. **Set realistic quality expectations** based on data source
2. **Review anomalies manually** for critical applications
3. **Implement data source validation** upstream
4. **Use confidence metrics** for decision making
5. **Document data quality issues** for future reference

### Performance Optimization
1. **Use batch processing** for large datasets
2. **Enable caching** for frequently accessed data
3. **Monitor memory usage** during processing
4. **Implement timeout handling** for long operations
5. **Use streaming** for very large datasets

---

## üìû Support

For technical support or questions about the Data Transformation System:

1. **Documentation**: Review this comprehensive guide
2. **Demo Interface**: Use the interactive demo for testing
3. **Error Logs**: Check browser console for detailed errors
4. **Performance Metrics**: Monitor processing statistics
5. **Quality Reports**: Review quality assessment results

The Data Transformation & Normalization System provides enterprise-grade data processing capabilities, ensuring your financial analysis is built on clean, validated, and standardized data foundations. 